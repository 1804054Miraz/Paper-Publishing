{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/1804054Miraz/Paper-Publishing/blob/main/ML_apply_in_on_Gamma_and_KatzFD_Band_with_full_channels.ipynb",
      "authorship_tag": "ABX9TyNQTYA3Y1Esv+SPOCNR+hE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1804054Miraz/Paper-Publishing/blob/main/ML_apply_in_on_Gamma_and_KatzFD_Band_with_full_channels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OzyTIM0dabvr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import statistics as st\n",
        "import scipy.stats as scst\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import entropy\n",
        "from scipy.stats import normaltest\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import time\n",
        "from sklearn.ensemble import BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Dataset/Features/merged_gamma_a_c.csv'\n",
        "merged_gamma_a_c = pd.read_csv(path)\n",
        "# merged_gamma_a_c=merged_gamma_a_c.drop(columns=['X_PS','Y_PS','nd_PS'], axis=False)\n",
        "merged_gamma_a_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "0uKUCmT7ap6e",
        "outputId": "5b6d2772-2d0c-45ff-ef54-e9c22ca74e2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        FP1_PS     FP2_PS      F7_PS       F8_PS    AF1_PS     AF2_PS  \\\n",
              "0     5.867765  16.136485  14.419578  107.004679  4.771000  10.412779   \n",
              "1     4.788753  11.568614  14.381443   75.048537  2.176075   8.500067   \n",
              "2     6.297802  29.544646  13.712807   97.931325  4.131878  13.930406   \n",
              "3     4.348968   9.195677  10.247385   62.184384  2.506088   6.808748   \n",
              "4     7.698942  15.086431  20.116347   61.128746  6.571280   8.982171   \n",
              "...        ...        ...        ...         ...       ...        ...   \n",
              "7617  2.437103   2.691105   9.169849    2.129555  1.467451   1.610917   \n",
              "7618  0.897495   1.245264   3.604244    3.566347  1.042233   1.365339   \n",
              "7619  1.251944   1.448347   6.375324    4.212090  0.632365   0.651843   \n",
              "7620  0.000000   0.000000   0.000000    0.000000  0.000000   0.000000   \n",
              "7621  3.617902   3.738929   5.852530    5.559126  3.810300   3.586122   \n",
              "\n",
              "         FZ_PS     F4_PS     F3_PS    FC6_PS  ...     PO8_PS    FCZ_PS  \\\n",
              "0     2.264702  4.967259  4.718617  2.227520  ...  31.407003  0.639929   \n",
              "1     1.558222  4.906503  3.750594  1.237990  ...  31.837468  0.481474   \n",
              "2     1.443750  4.954165  4.627834  2.631432  ...  39.507001  0.403271   \n",
              "3     1.321086  3.921911  3.681952  1.816489  ...  30.478540  0.450695   \n",
              "4     3.578223  4.040258  6.796313  2.204725  ...  55.854653  1.011451   \n",
              "...        ...       ...       ...       ...  ...        ...       ...   \n",
              "7617  0.581611  2.188392  2.580653  1.218395  ...   5.024580  0.227139   \n",
              "7618  0.834950  1.492575  0.902565  1.093884  ...   3.040292  0.398802   \n",
              "7619  0.297628  0.621490  0.765336  1.009508  ...   2.070562  0.132006   \n",
              "7620  0.000000  0.000000  0.000000  0.000000  ...   0.000000  0.000000   \n",
              "7621  3.760634  3.979930  5.524031  3.403491  ...   4.453148  3.155204   \n",
              "\n",
              "        POZ_PS     OZ_PS     P2_PS     P1_PS    CPZ_PS     nd_PS      Y_PS  \\\n",
              "0     3.175360  7.257440  1.171091  1.727645  0.303052  5.626485  6.090333   \n",
              "1     1.360249  3.002968  0.452312  0.873387  0.169722  4.693551  3.472028   \n",
              "2     1.391440  2.908869  0.790318  1.077771  0.227142  6.266331  3.612442   \n",
              "3     1.121842  2.162650  0.753562  0.999099  0.180620  4.211706  6.950914   \n",
              "4     3.663678  5.646425  1.918202  2.340282  0.437771  7.413797  7.107321   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7617  3.721454  4.377724  1.713244  1.729774  0.453551  5.866098  3.061931   \n",
              "7618  3.180998  2.880482  2.019003  1.853624  0.785453  2.408728  3.512361   \n",
              "7619  1.298873  1.126842  0.855509  0.550932  0.247462  1.363607  3.663259   \n",
              "7620  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7621  4.027627  3.094130  2.927279  3.796067  3.164739  3.551407  9.684160   \n",
              "\n",
              "         label  \n",
              "0     addicted  \n",
              "1     addicted  \n",
              "2     addicted  \n",
              "3     addicted  \n",
              "4     addicted  \n",
              "...        ...  \n",
              "7617    normal  \n",
              "7618    normal  \n",
              "7619    normal  \n",
              "7620    normal  \n",
              "7621    normal  \n",
              "\n",
              "[7622 rows x 65 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be8163a8-1fcb-4104-a25a-617426f9234e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FP1_PS</th>\n",
              "      <th>FP2_PS</th>\n",
              "      <th>F7_PS</th>\n",
              "      <th>F8_PS</th>\n",
              "      <th>AF1_PS</th>\n",
              "      <th>AF2_PS</th>\n",
              "      <th>FZ_PS</th>\n",
              "      <th>F4_PS</th>\n",
              "      <th>F3_PS</th>\n",
              "      <th>FC6_PS</th>\n",
              "      <th>...</th>\n",
              "      <th>PO8_PS</th>\n",
              "      <th>FCZ_PS</th>\n",
              "      <th>POZ_PS</th>\n",
              "      <th>OZ_PS</th>\n",
              "      <th>P2_PS</th>\n",
              "      <th>P1_PS</th>\n",
              "      <th>CPZ_PS</th>\n",
              "      <th>nd_PS</th>\n",
              "      <th>Y_PS</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.867765</td>\n",
              "      <td>16.136485</td>\n",
              "      <td>14.419578</td>\n",
              "      <td>107.004679</td>\n",
              "      <td>4.771000</td>\n",
              "      <td>10.412779</td>\n",
              "      <td>2.264702</td>\n",
              "      <td>4.967259</td>\n",
              "      <td>4.718617</td>\n",
              "      <td>2.227520</td>\n",
              "      <td>...</td>\n",
              "      <td>31.407003</td>\n",
              "      <td>0.639929</td>\n",
              "      <td>3.175360</td>\n",
              "      <td>7.257440</td>\n",
              "      <td>1.171091</td>\n",
              "      <td>1.727645</td>\n",
              "      <td>0.303052</td>\n",
              "      <td>5.626485</td>\n",
              "      <td>6.090333</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.788753</td>\n",
              "      <td>11.568614</td>\n",
              "      <td>14.381443</td>\n",
              "      <td>75.048537</td>\n",
              "      <td>2.176075</td>\n",
              "      <td>8.500067</td>\n",
              "      <td>1.558222</td>\n",
              "      <td>4.906503</td>\n",
              "      <td>3.750594</td>\n",
              "      <td>1.237990</td>\n",
              "      <td>...</td>\n",
              "      <td>31.837468</td>\n",
              "      <td>0.481474</td>\n",
              "      <td>1.360249</td>\n",
              "      <td>3.002968</td>\n",
              "      <td>0.452312</td>\n",
              "      <td>0.873387</td>\n",
              "      <td>0.169722</td>\n",
              "      <td>4.693551</td>\n",
              "      <td>3.472028</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.297802</td>\n",
              "      <td>29.544646</td>\n",
              "      <td>13.712807</td>\n",
              "      <td>97.931325</td>\n",
              "      <td>4.131878</td>\n",
              "      <td>13.930406</td>\n",
              "      <td>1.443750</td>\n",
              "      <td>4.954165</td>\n",
              "      <td>4.627834</td>\n",
              "      <td>2.631432</td>\n",
              "      <td>...</td>\n",
              "      <td>39.507001</td>\n",
              "      <td>0.403271</td>\n",
              "      <td>1.391440</td>\n",
              "      <td>2.908869</td>\n",
              "      <td>0.790318</td>\n",
              "      <td>1.077771</td>\n",
              "      <td>0.227142</td>\n",
              "      <td>6.266331</td>\n",
              "      <td>3.612442</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.348968</td>\n",
              "      <td>9.195677</td>\n",
              "      <td>10.247385</td>\n",
              "      <td>62.184384</td>\n",
              "      <td>2.506088</td>\n",
              "      <td>6.808748</td>\n",
              "      <td>1.321086</td>\n",
              "      <td>3.921911</td>\n",
              "      <td>3.681952</td>\n",
              "      <td>1.816489</td>\n",
              "      <td>...</td>\n",
              "      <td>30.478540</td>\n",
              "      <td>0.450695</td>\n",
              "      <td>1.121842</td>\n",
              "      <td>2.162650</td>\n",
              "      <td>0.753562</td>\n",
              "      <td>0.999099</td>\n",
              "      <td>0.180620</td>\n",
              "      <td>4.211706</td>\n",
              "      <td>6.950914</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.698942</td>\n",
              "      <td>15.086431</td>\n",
              "      <td>20.116347</td>\n",
              "      <td>61.128746</td>\n",
              "      <td>6.571280</td>\n",
              "      <td>8.982171</td>\n",
              "      <td>3.578223</td>\n",
              "      <td>4.040258</td>\n",
              "      <td>6.796313</td>\n",
              "      <td>2.204725</td>\n",
              "      <td>...</td>\n",
              "      <td>55.854653</td>\n",
              "      <td>1.011451</td>\n",
              "      <td>3.663678</td>\n",
              "      <td>5.646425</td>\n",
              "      <td>1.918202</td>\n",
              "      <td>2.340282</td>\n",
              "      <td>0.437771</td>\n",
              "      <td>7.413797</td>\n",
              "      <td>7.107321</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7617</th>\n",
              "      <td>2.437103</td>\n",
              "      <td>2.691105</td>\n",
              "      <td>9.169849</td>\n",
              "      <td>2.129555</td>\n",
              "      <td>1.467451</td>\n",
              "      <td>1.610917</td>\n",
              "      <td>0.581611</td>\n",
              "      <td>2.188392</td>\n",
              "      <td>2.580653</td>\n",
              "      <td>1.218395</td>\n",
              "      <td>...</td>\n",
              "      <td>5.024580</td>\n",
              "      <td>0.227139</td>\n",
              "      <td>3.721454</td>\n",
              "      <td>4.377724</td>\n",
              "      <td>1.713244</td>\n",
              "      <td>1.729774</td>\n",
              "      <td>0.453551</td>\n",
              "      <td>5.866098</td>\n",
              "      <td>3.061931</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7618</th>\n",
              "      <td>0.897495</td>\n",
              "      <td>1.245264</td>\n",
              "      <td>3.604244</td>\n",
              "      <td>3.566347</td>\n",
              "      <td>1.042233</td>\n",
              "      <td>1.365339</td>\n",
              "      <td>0.834950</td>\n",
              "      <td>1.492575</td>\n",
              "      <td>0.902565</td>\n",
              "      <td>1.093884</td>\n",
              "      <td>...</td>\n",
              "      <td>3.040292</td>\n",
              "      <td>0.398802</td>\n",
              "      <td>3.180998</td>\n",
              "      <td>2.880482</td>\n",
              "      <td>2.019003</td>\n",
              "      <td>1.853624</td>\n",
              "      <td>0.785453</td>\n",
              "      <td>2.408728</td>\n",
              "      <td>3.512361</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7619</th>\n",
              "      <td>1.251944</td>\n",
              "      <td>1.448347</td>\n",
              "      <td>6.375324</td>\n",
              "      <td>4.212090</td>\n",
              "      <td>0.632365</td>\n",
              "      <td>0.651843</td>\n",
              "      <td>0.297628</td>\n",
              "      <td>0.621490</td>\n",
              "      <td>0.765336</td>\n",
              "      <td>1.009508</td>\n",
              "      <td>...</td>\n",
              "      <td>2.070562</td>\n",
              "      <td>0.132006</td>\n",
              "      <td>1.298873</td>\n",
              "      <td>1.126842</td>\n",
              "      <td>0.855509</td>\n",
              "      <td>0.550932</td>\n",
              "      <td>0.247462</td>\n",
              "      <td>1.363607</td>\n",
              "      <td>3.663259</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7620</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7621</th>\n",
              "      <td>3.617902</td>\n",
              "      <td>3.738929</td>\n",
              "      <td>5.852530</td>\n",
              "      <td>5.559126</td>\n",
              "      <td>3.810300</td>\n",
              "      <td>3.586122</td>\n",
              "      <td>3.760634</td>\n",
              "      <td>3.979930</td>\n",
              "      <td>5.524031</td>\n",
              "      <td>3.403491</td>\n",
              "      <td>...</td>\n",
              "      <td>4.453148</td>\n",
              "      <td>3.155204</td>\n",
              "      <td>4.027627</td>\n",
              "      <td>3.094130</td>\n",
              "      <td>2.927279</td>\n",
              "      <td>3.796067</td>\n",
              "      <td>3.164739</td>\n",
              "      <td>3.551407</td>\n",
              "      <td>9.684160</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7622 rows × 65 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be8163a8-1fcb-4104-a25a-617426f9234e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be8163a8-1fcb-4104-a25a-617426f9234e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be8163a8-1fcb-4104-a25a-617426f9234e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1d1ef51-64ec-4e5a-bf40-895768cd57db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1d1ef51-64ec-4e5a-bf40-895768cd57db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1d1ef51-64ec-4e5a-bf40-895768cd57db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_gamma_a_c"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_gamma_a_c = merged_gamma_a_c.replace(0, merged_gamma_a_c.mean(numeric_only=True))\n",
        "merged_gamma_a_c = merged_gamma_a_c.drop(7620)\n",
        "merged_gamma_a_c = merged_gamma_a_c.reset_index(drop=True)\n",
        "merged_gamma_a_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "iSG_DyT452q_",
        "outputId": "c1947509-743d-427b-d20e-1012bd7d26bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        FP1_PS     FP2_PS      F7_PS       F8_PS    AF1_PS     AF2_PS  \\\n",
              "0     5.867765  16.136485  14.419578  107.004679  4.771000  10.412779   \n",
              "1     4.788753  11.568614  14.381443   75.048537  2.176075   8.500067   \n",
              "2     6.297802  29.544646  13.712807   97.931325  4.131878  13.930406   \n",
              "3     4.348968   9.195677  10.247385   62.184384  2.506088   6.808748   \n",
              "4     7.698942  15.086431  20.116347   61.128746  6.571280   8.982171   \n",
              "...        ...        ...        ...         ...       ...        ...   \n",
              "7616  1.684572   1.623761   9.112097    2.782111  1.144432   0.884217   \n",
              "7617  2.437103   2.691105   9.169849    2.129555  1.467451   1.610917   \n",
              "7618  0.897495   1.245264   3.604244    3.566347  1.042233   1.365339   \n",
              "7619  1.251944   1.448347   6.375324    4.212090  0.632365   0.651843   \n",
              "7620  3.617902   3.738929   5.852530    5.559126  3.810300   3.586122   \n",
              "\n",
              "         FZ_PS     F4_PS     F3_PS    FC6_PS  ...     PO8_PS    FCZ_PS  \\\n",
              "0     2.264702  4.967259  4.718617  2.227520  ...  31.407003  0.639929   \n",
              "1     1.558222  4.906503  3.750594  1.237990  ...  31.837468  0.481474   \n",
              "2     1.443750  4.954165  4.627834  2.631432  ...  39.507001  0.403271   \n",
              "3     1.321086  3.921911  3.681952  1.816489  ...  30.478540  0.450695   \n",
              "4     3.578223  4.040258  6.796313  2.204725  ...  55.854653  1.011451   \n",
              "...        ...       ...       ...       ...  ...        ...       ...   \n",
              "7616  1.269359  0.880600  1.205278  0.957745  ...   2.408939  0.174153   \n",
              "7617  0.581611  2.188392  2.580653  1.218395  ...   5.024580  0.227139   \n",
              "7618  0.834950  1.492575  0.902565  1.093884  ...   3.040292  0.398802   \n",
              "7619  0.297628  0.621490  0.765336  1.009508  ...   2.070562  0.132006   \n",
              "7620  3.760634  3.979930  5.524031  3.403491  ...   4.453148  3.155204   \n",
              "\n",
              "        POZ_PS     OZ_PS     P2_PS     P1_PS    CPZ_PS     nd_PS      Y_PS  \\\n",
              "0     3.175360  7.257440  1.171091  1.727645  0.303052  5.626485  6.090333   \n",
              "1     1.360249  3.002968  0.452312  0.873387  0.169722  4.693551  3.472028   \n",
              "2     1.391440  2.908869  0.790318  1.077771  0.227142  6.266331  3.612442   \n",
              "3     1.121842  2.162650  0.753562  0.999099  0.180620  4.211706  6.950914   \n",
              "4     3.663678  5.646425  1.918202  2.340282  0.437771  7.413797  7.107321   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7616  0.867184  1.234990  0.535141  0.633024  0.261792  1.058754  6.116856   \n",
              "7617  3.721454  4.377724  1.713244  1.729774  0.453551  5.866098  3.061931   \n",
              "7618  3.180998  2.880482  2.019003  1.853624  0.785453  2.408728  3.512361   \n",
              "7619  1.298873  1.126842  0.855509  0.550932  0.247462  1.363607  3.663259   \n",
              "7620  4.027627  3.094130  2.927279  3.796067  3.164739  3.551407  9.684160   \n",
              "\n",
              "         label  \n",
              "0     addicted  \n",
              "1     addicted  \n",
              "2     addicted  \n",
              "3     addicted  \n",
              "4     addicted  \n",
              "...        ...  \n",
              "7616    normal  \n",
              "7617    normal  \n",
              "7618    normal  \n",
              "7619    normal  \n",
              "7620    normal  \n",
              "\n",
              "[7621 rows x 65 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-641a2843-3b78-41b6-b52f-a751a187d3a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FP1_PS</th>\n",
              "      <th>FP2_PS</th>\n",
              "      <th>F7_PS</th>\n",
              "      <th>F8_PS</th>\n",
              "      <th>AF1_PS</th>\n",
              "      <th>AF2_PS</th>\n",
              "      <th>FZ_PS</th>\n",
              "      <th>F4_PS</th>\n",
              "      <th>F3_PS</th>\n",
              "      <th>FC6_PS</th>\n",
              "      <th>...</th>\n",
              "      <th>PO8_PS</th>\n",
              "      <th>FCZ_PS</th>\n",
              "      <th>POZ_PS</th>\n",
              "      <th>OZ_PS</th>\n",
              "      <th>P2_PS</th>\n",
              "      <th>P1_PS</th>\n",
              "      <th>CPZ_PS</th>\n",
              "      <th>nd_PS</th>\n",
              "      <th>Y_PS</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.867765</td>\n",
              "      <td>16.136485</td>\n",
              "      <td>14.419578</td>\n",
              "      <td>107.004679</td>\n",
              "      <td>4.771000</td>\n",
              "      <td>10.412779</td>\n",
              "      <td>2.264702</td>\n",
              "      <td>4.967259</td>\n",
              "      <td>4.718617</td>\n",
              "      <td>2.227520</td>\n",
              "      <td>...</td>\n",
              "      <td>31.407003</td>\n",
              "      <td>0.639929</td>\n",
              "      <td>3.175360</td>\n",
              "      <td>7.257440</td>\n",
              "      <td>1.171091</td>\n",
              "      <td>1.727645</td>\n",
              "      <td>0.303052</td>\n",
              "      <td>5.626485</td>\n",
              "      <td>6.090333</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.788753</td>\n",
              "      <td>11.568614</td>\n",
              "      <td>14.381443</td>\n",
              "      <td>75.048537</td>\n",
              "      <td>2.176075</td>\n",
              "      <td>8.500067</td>\n",
              "      <td>1.558222</td>\n",
              "      <td>4.906503</td>\n",
              "      <td>3.750594</td>\n",
              "      <td>1.237990</td>\n",
              "      <td>...</td>\n",
              "      <td>31.837468</td>\n",
              "      <td>0.481474</td>\n",
              "      <td>1.360249</td>\n",
              "      <td>3.002968</td>\n",
              "      <td>0.452312</td>\n",
              "      <td>0.873387</td>\n",
              "      <td>0.169722</td>\n",
              "      <td>4.693551</td>\n",
              "      <td>3.472028</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.297802</td>\n",
              "      <td>29.544646</td>\n",
              "      <td>13.712807</td>\n",
              "      <td>97.931325</td>\n",
              "      <td>4.131878</td>\n",
              "      <td>13.930406</td>\n",
              "      <td>1.443750</td>\n",
              "      <td>4.954165</td>\n",
              "      <td>4.627834</td>\n",
              "      <td>2.631432</td>\n",
              "      <td>...</td>\n",
              "      <td>39.507001</td>\n",
              "      <td>0.403271</td>\n",
              "      <td>1.391440</td>\n",
              "      <td>2.908869</td>\n",
              "      <td>0.790318</td>\n",
              "      <td>1.077771</td>\n",
              "      <td>0.227142</td>\n",
              "      <td>6.266331</td>\n",
              "      <td>3.612442</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.348968</td>\n",
              "      <td>9.195677</td>\n",
              "      <td>10.247385</td>\n",
              "      <td>62.184384</td>\n",
              "      <td>2.506088</td>\n",
              "      <td>6.808748</td>\n",
              "      <td>1.321086</td>\n",
              "      <td>3.921911</td>\n",
              "      <td>3.681952</td>\n",
              "      <td>1.816489</td>\n",
              "      <td>...</td>\n",
              "      <td>30.478540</td>\n",
              "      <td>0.450695</td>\n",
              "      <td>1.121842</td>\n",
              "      <td>2.162650</td>\n",
              "      <td>0.753562</td>\n",
              "      <td>0.999099</td>\n",
              "      <td>0.180620</td>\n",
              "      <td>4.211706</td>\n",
              "      <td>6.950914</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.698942</td>\n",
              "      <td>15.086431</td>\n",
              "      <td>20.116347</td>\n",
              "      <td>61.128746</td>\n",
              "      <td>6.571280</td>\n",
              "      <td>8.982171</td>\n",
              "      <td>3.578223</td>\n",
              "      <td>4.040258</td>\n",
              "      <td>6.796313</td>\n",
              "      <td>2.204725</td>\n",
              "      <td>...</td>\n",
              "      <td>55.854653</td>\n",
              "      <td>1.011451</td>\n",
              "      <td>3.663678</td>\n",
              "      <td>5.646425</td>\n",
              "      <td>1.918202</td>\n",
              "      <td>2.340282</td>\n",
              "      <td>0.437771</td>\n",
              "      <td>7.413797</td>\n",
              "      <td>7.107321</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7616</th>\n",
              "      <td>1.684572</td>\n",
              "      <td>1.623761</td>\n",
              "      <td>9.112097</td>\n",
              "      <td>2.782111</td>\n",
              "      <td>1.144432</td>\n",
              "      <td>0.884217</td>\n",
              "      <td>1.269359</td>\n",
              "      <td>0.880600</td>\n",
              "      <td>1.205278</td>\n",
              "      <td>0.957745</td>\n",
              "      <td>...</td>\n",
              "      <td>2.408939</td>\n",
              "      <td>0.174153</td>\n",
              "      <td>0.867184</td>\n",
              "      <td>1.234990</td>\n",
              "      <td>0.535141</td>\n",
              "      <td>0.633024</td>\n",
              "      <td>0.261792</td>\n",
              "      <td>1.058754</td>\n",
              "      <td>6.116856</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7617</th>\n",
              "      <td>2.437103</td>\n",
              "      <td>2.691105</td>\n",
              "      <td>9.169849</td>\n",
              "      <td>2.129555</td>\n",
              "      <td>1.467451</td>\n",
              "      <td>1.610917</td>\n",
              "      <td>0.581611</td>\n",
              "      <td>2.188392</td>\n",
              "      <td>2.580653</td>\n",
              "      <td>1.218395</td>\n",
              "      <td>...</td>\n",
              "      <td>5.024580</td>\n",
              "      <td>0.227139</td>\n",
              "      <td>3.721454</td>\n",
              "      <td>4.377724</td>\n",
              "      <td>1.713244</td>\n",
              "      <td>1.729774</td>\n",
              "      <td>0.453551</td>\n",
              "      <td>5.866098</td>\n",
              "      <td>3.061931</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7618</th>\n",
              "      <td>0.897495</td>\n",
              "      <td>1.245264</td>\n",
              "      <td>3.604244</td>\n",
              "      <td>3.566347</td>\n",
              "      <td>1.042233</td>\n",
              "      <td>1.365339</td>\n",
              "      <td>0.834950</td>\n",
              "      <td>1.492575</td>\n",
              "      <td>0.902565</td>\n",
              "      <td>1.093884</td>\n",
              "      <td>...</td>\n",
              "      <td>3.040292</td>\n",
              "      <td>0.398802</td>\n",
              "      <td>3.180998</td>\n",
              "      <td>2.880482</td>\n",
              "      <td>2.019003</td>\n",
              "      <td>1.853624</td>\n",
              "      <td>0.785453</td>\n",
              "      <td>2.408728</td>\n",
              "      <td>3.512361</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7619</th>\n",
              "      <td>1.251944</td>\n",
              "      <td>1.448347</td>\n",
              "      <td>6.375324</td>\n",
              "      <td>4.212090</td>\n",
              "      <td>0.632365</td>\n",
              "      <td>0.651843</td>\n",
              "      <td>0.297628</td>\n",
              "      <td>0.621490</td>\n",
              "      <td>0.765336</td>\n",
              "      <td>1.009508</td>\n",
              "      <td>...</td>\n",
              "      <td>2.070562</td>\n",
              "      <td>0.132006</td>\n",
              "      <td>1.298873</td>\n",
              "      <td>1.126842</td>\n",
              "      <td>0.855509</td>\n",
              "      <td>0.550932</td>\n",
              "      <td>0.247462</td>\n",
              "      <td>1.363607</td>\n",
              "      <td>3.663259</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7620</th>\n",
              "      <td>3.617902</td>\n",
              "      <td>3.738929</td>\n",
              "      <td>5.852530</td>\n",
              "      <td>5.559126</td>\n",
              "      <td>3.810300</td>\n",
              "      <td>3.586122</td>\n",
              "      <td>3.760634</td>\n",
              "      <td>3.979930</td>\n",
              "      <td>5.524031</td>\n",
              "      <td>3.403491</td>\n",
              "      <td>...</td>\n",
              "      <td>4.453148</td>\n",
              "      <td>3.155204</td>\n",
              "      <td>4.027627</td>\n",
              "      <td>3.094130</td>\n",
              "      <td>2.927279</td>\n",
              "      <td>3.796067</td>\n",
              "      <td>3.164739</td>\n",
              "      <td>3.551407</td>\n",
              "      <td>9.684160</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7621 rows × 65 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-641a2843-3b78-41b6-b52f-a751a187d3a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-641a2843-3b78-41b6-b52f-a751a187d3a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-641a2843-3b78-41b6-b52f-a751a187d3a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8040c5e2-9ab6-4fe3-8d8b-0c0aa2423d44\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8040c5e2-9ab6-4fe3-8d8b-0c0aa2423d44')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8040c5e2-9ab6-4fe3-8d8b-0c0aa2423d44 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_gamma_a_c"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = merged_gamma_a_c.iloc[:, :-1]\n",
        "y = merged_gamma_a_c.iloc[:, -1]\n",
        "\n",
        "# Encode the target variable if it's categorical\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "\n",
        "svm_classifier = make_pipeline(StandardScaler(), SVC())\n",
        "svm_predictions = cross_val_predict(svm_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "svm_accuracy = accuracy_score(y_encoded, svm_predictions)\n",
        "svm_precision = precision_score(y_encoded, svm_predictions)\n",
        "svm_recall = recall_score(y_encoded, svm_predictions)\n",
        "svm_f1 = f1_score(y_encoded, svm_predictions)\n",
        "\n",
        "\n",
        "print(\"SVM Metrics:\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"F1 Score:\", svm_f1)\n",
        "# print(\"Processing Time:\", svm_processing_time)\n",
        "\n",
        "# XGBoost\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "xgb_predictions = cross_val_predict(xgb_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "xgb_accuracy = accuracy_score(y_encoded, xgb_predictions)\n",
        "xgb_precision = precision_score(y_encoded, xgb_predictions)\n",
        "xgb_recall = recall_score(y_encoded, xgb_predictions)\n",
        "xgb_f1 = f1_score(y_encoded, xgb_predictions)\n",
        "\n",
        "\n",
        "print(\"\\nXGBoost Metrics:\")\n",
        "print(\"Accuracy:\", xgb_accuracy)\n",
        "print(\"Precision:\", xgb_precision)\n",
        "print(\"Recall:\", xgb_recall)\n",
        "print(\"F1 Score:\", xgb_f1)\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_predictions = cross_val_predict(rf_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "rf_accuracy = accuracy_score(y_encoded, rf_predictions)\n",
        "rf_precision = precision_score(y_encoded, rf_predictions)\n",
        "rf_recall = recall_score(y_encoded, rf_predictions)\n",
        "rf_f1 = f1_score(y_encoded, rf_predictions)\n",
        "\n",
        "print(\"\\nRandom Forest Metrics:\")\n",
        "print(\"Accuracy:\", rf_accuracy)\n",
        "print(\"Precision:\", rf_precision)\n",
        "print(\"Recall:\", rf_recall)\n",
        "print(\"F1 Score:\", rf_f1)\n",
        "\n",
        "\n",
        "# Ensemble Subspace of k-Nearest Neighbors\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "ensemble_knn_classifier = BaggingClassifier(base_estimator=knn_classifier, n_estimators=10, random_state=42)\n",
        "\n",
        "ensemble_knn_scores = cross_val_predict(ensemble_knn_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "ensemble_knn_accuracy = accuracy_score(y_encoded, ensemble_knn_scores)\n",
        "ensemble_knn_precision = precision_score(y_encoded, ensemble_knn_scores)\n",
        "ensemble_knn_recall = recall_score(y_encoded, ensemble_knn_scores)\n",
        "ensemble_knn_f1 = f1_score(y_encoded, ensemble_knn_scores)\n",
        "\n",
        "print(\"\\nEnsemble Subspace of k-Nearest Neighbors Metrics:\")\n",
        "print(\"Accuracy:\", ensemble_knn_accuracy)\n",
        "print(\"Precision:\", ensemble_knn_precision)\n",
        "print(\"Recall:\", ensemble_knn_recall)\n",
        "print(\"F1 Score:\", ensemble_knn_f1)\n",
        "# print(\"Processing Time:\", ensemble_knn_processing_time)\n",
        "\n",
        "# LSTM Model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=input_shape, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Convert DataFrame to numpy array\n",
        "X_np = X.values\n",
        "X_np = X_np.reshape((X_np.shape[0], 1, X_np.shape[1]))\n",
        "\n",
        "# 10-fold cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_idx, test_idx in kfold.split(X_np):\n",
        "    X_train, X_test = X_np[train_idx], X_np[test_idx]\n",
        "    y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
        "\n",
        "    # Create and fit LSTM model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "    lstm_model = create_lstm_model(input_shape)\n",
        "    lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_probs = lstm_model.predict(X_test)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Evaluate metrics\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\nLSTM Metrics:\")\n",
        "print(\"LSTM Model Accuracy:\", np.mean(accuracy_scores))\n",
        "print(\"LSTM Model Precision:\", np.mean(precision_scores))\n",
        "print(\"LSTM Model Recall:\", np.mean(recall_scores))\n",
        "print(\"LSTM Model F1 Score:\", np.mean(f1_scores))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iFxn1s6b2dH",
        "outputId": "59a74da5-41eb-4ec5-c80a-7fa0b73626b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Metrics:\n",
            "Accuracy: 0.8463456239338669\n",
            "Precision: 0.871376301716859\n",
            "Recall: 0.8125984251968504\n",
            "F1 Score: 0.8409615645796552\n",
            "\n",
            "XGBoost Metrics:\n",
            "Accuracy: 0.9574858942396011\n",
            "Precision: 0.9548538622129437\n",
            "Recall: 0.9603674540682414\n",
            "F1 Score: 0.9576027218005757\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.9278309933079648\n",
            "Precision: 0.9227178423236515\n",
            "Recall: 0.9338582677165355\n",
            "F1 Score: 0.9282546308374642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble Subspace of k-Nearest Neighbors Metrics:\n",
            "Accuracy: 0.9430520929011941\n",
            "Precision: 0.9421162912519644\n",
            "Recall: 0.9440944881889763\n",
            "F1 Score: 0.9431043523859465\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "\n",
            "LSTM Metrics:\n",
            "LSTM Model Accuracy: 0.9168118320072376\n",
            "LSTM Model Precision: 0.9090778249380234\n",
            "LSTM Model Recall: 0.9282679163961584\n",
            "LSTM Model F1 Score: 0.9178553475883179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost lightgbm catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33HZ2wbSBhcb",
        "outputId": "56df3d88-f385-4fd3-fb63-2cc75b5bd7b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.52.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# LightGBM\n",
        "lgb_classifier = lgb.LGBMClassifier()\n",
        "lgb_predictions = cross_val_predict(lgb_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "lgb_accuracy = accuracy_score(y_encoded, lgb_predictions)\n",
        "lgb_precision = precision_score(y_encoded, lgb_predictions)\n",
        "lgb_recall = recall_score(y_encoded, lgb_predictions)\n",
        "lgb_f1 = f1_score(y_encoded, lgb_predictions)\n",
        "\n",
        "print(\"\\nLightGBM Metrics:\")\n",
        "print(\"Accuracy:\", lgb_accuracy)\n",
        "print(\"Precision:\", lgb_precision)\n",
        "print(\"Recall:\", lgb_recall)\n",
        "print(\"F1 Score:\", lgb_f1)\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# CatBoost\n",
        "catboost_classifier = CatBoostClassifier(verbose=0)\n",
        "catboost_predictions = cross_val_predict(catboost_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "catboost_accuracy = accuracy_score(y_encoded, catboost_predictions)\n",
        "catboost_precision = precision_score(y_encoded, catboost_predictions)\n",
        "catboost_recall = recall_score(y_encoded, catboost_predictions)\n",
        "catboost_f1 = f1_score(y_encoded, catboost_predictions)\n",
        "\n",
        "print(\"\\nCatBoost Metrics:\")\n",
        "print(\"Accuracy:\", catboost_accuracy)\n",
        "print(\"Precision:\", catboost_precision)\n",
        "print(\"Recall:\", catboost_recall)\n",
        "print(\"F1 Score:\", catboost_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uovevnZSBShT",
        "outputId": "459c11ce-0f56-4838-c8f5-4209165f285a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3438, number of negative: 3420\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6858, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501312 -> initscore=0.005249\n",
            "[LightGBM] [Info] Start training from score 0.005249\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005825 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006047 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005929 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3429, number of negative: 3430\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005865 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000292\n",
            "[LightGBM] [Info] Start training from score -0.000292\n",
            "[LightGBM] [Info] Number of positive: 3416, number of negative: 3443\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009646 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498032 -> initscore=-0.007873\n",
            "[LightGBM] [Info] Start training from score -0.007873\n",
            "[LightGBM] [Info] Number of positive: 3421, number of negative: 3438\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034004 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498761 -> initscore=-0.004957\n",
            "[LightGBM] [Info] Start training from score -0.004957\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3430, number of negative: 3429\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009330 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000292\n",
            "[LightGBM] [Info] Start training from score 0.000292\n",
            "[LightGBM] [Info] Number of positive: 3426, number of negative: 3433\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499490 -> initscore=-0.002041\n",
            "[LightGBM] [Info] Start training from score -0.002041\n",
            "\n",
            "LightGBM Metrics:\n",
            "Accuracy: 0.9523684555832568\n",
            "Precision: 0.9491790461297889\n",
            "Recall: 0.9559055118110236\n",
            "F1 Score: 0.9525304040800313\n",
            "\n",
            "CatBoost Metrics:\n",
            "Accuracy: 0.958404408870227\n",
            "Precision: 0.9544626593806922\n",
            "Recall: 0.9627296587926509\n",
            "F1 Score: 0.958578335293349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Prepare the data\n",
        "X = merged_gamma_a_c.iloc[:, :-1]\n",
        "y = merged_gamma_a_c.iloc[:, -1]\n",
        "\n",
        "# Encode the target variable if it's categorical\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Define individual models\n",
        "xgb_classifier = XGBClassifier()\n",
        "lgb_classifier = lgb.LGBMClassifier()\n",
        "catboost_classifier = CatBoostClassifier(verbose=0)\n",
        "\n",
        "# Define voting classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_classifier),\n",
        "        ('lgb', lgb_classifier),\n",
        "        ('catboost', catboost_classifier)\n",
        "    ],\n",
        "    voting='soft'  # 'hard' for majority voting, 'soft' for weighted probabilities\n",
        ")\n",
        "\n",
        "# Define k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score),\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1': make_scorer(f1_score)}\n",
        "\n",
        "voting_scores = cross_validate(voting_classifier, X, y_encoded, cv=kf, scoring=scoring)\n",
        "\n",
        "print(\"\\nVoting Ensemble Metrics:\")\n",
        "print(\"Accuracy:\", np.mean(voting_scores['test_accuracy']))\n",
        "print(\"Precision:\", np.mean(voting_scores['test_precision']))\n",
        "print(\"Recall:\", np.mean(voting_scores['test_recall']))\n",
        "print(\"F1 Score:\", np.mean(voting_scores['test_f1']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89MY-ELSPlmU",
        "outputId": "d83c7eae-4ce8-4920-c31e-079d04bbfd25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3438, number of negative: 3420\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6858, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501312 -> initscore=0.005249\n",
            "[LightGBM] [Info] Start training from score 0.005249\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006039 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005974 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005963 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3429, number of negative: 3430\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005935 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000292\n",
            "[LightGBM] [Info] Start training from score -0.000292\n",
            "[LightGBM] [Info] Number of positive: 3416, number of negative: 3443\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005850 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498032 -> initscore=-0.007873\n",
            "[LightGBM] [Info] Start training from score -0.007873\n",
            "[LightGBM] [Info] Number of positive: 3421, number of negative: 3438\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005880 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498761 -> initscore=-0.004957\n",
            "[LightGBM] [Info] Start training from score -0.004957\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005940 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3430, number of negative: 3429\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009678 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000292\n",
            "[LightGBM] [Info] Start training from score 0.000292\n",
            "[LightGBM] [Info] Number of positive: 3426, number of negative: 3433\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005942 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499490 -> initscore=-0.002041\n",
            "[LightGBM] [Info] Start training from score -0.002041\n",
            "\n",
            "Voting Ensemble Metrics:\n",
            "Accuracy: 0.9595860723831539\n",
            "Precision: 0.9570982860319477\n",
            "Recall: 0.9624815222280223\n",
            "F1 Score: 0.9596946866389853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming 'merged_gamma_a_c' is your dataset\n",
        "X = merged_gamma_a_c.iloc[:, :-1]\n",
        "y = merged_gamma_a_c.iloc[:, -1]\n",
        "\n",
        "# Encode the target variable if it's categorical\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Define individual models\n",
        "xgb_classifier = XGBClassifier()\n",
        "lgb_classifier = lgb.LGBMClassifier()\n",
        "catboost_classifier = CatBoostClassifier(verbose=0)\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define voting classifier with Random Forest included\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_classifier),\n",
        "        ('lgb', lgb_classifier),\n",
        "        ('catboost', catboost_classifier),\n",
        "        ('rf', rf_classifier)\n",
        "    ],\n",
        "    voting='soft'  # 'hard' for majority voting, 'soft' for weighted probabilities\n",
        ")\n",
        "\n",
        "# Define k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score),\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1': make_scorer(f1_score)}\n",
        "\n",
        "voting_scores = cross_validate(voting_classifier, X, y_encoded, cv=kf, scoring=scoring)\n",
        "\n",
        "print(\"\\nVoting Ensemble Metrics:\")\n",
        "print(\"Accuracy:\", np.mean(voting_scores['test_accuracy']))\n",
        "print(\"Precision:\", np.mean(voting_scores['test_precision']))\n",
        "print(\"Recall:\", np.mean(voting_scores['test_recall']))\n",
        "print(\"F1 Score:\", np.mean(voting_scores['test_f1']))\n"
      ],
      "metadata": {
        "id": "tCryYPZ-kDBK",
        "outputId": "4ea210dc-6d56-4836-a3aa-2e42b9e913dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3438, number of negative: 3420\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005519 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6858, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501312 -> initscore=0.005249\n",
            "[LightGBM] [Info] Start training from score 0.005249\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005766 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3429, number of negative: 3430\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000292\n",
            "[LightGBM] [Info] Start training from score -0.000292\n",
            "[LightGBM] [Info] Number of positive: 3416, number of negative: 3443\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498032 -> initscore=-0.007873\n",
            "[LightGBM] [Info] Start training from score -0.007873\n",
            "[LightGBM] [Info] Number of positive: 3421, number of negative: 3438\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005924 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498761 -> initscore=-0.004957\n",
            "[LightGBM] [Info] Start training from score -0.004957\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3430, number of negative: 3429\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000292\n",
            "[LightGBM] [Info] Start training from score 0.000292\n",
            "[LightGBM] [Info] Number of positive: 3426, number of negative: 3433\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005798 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16320\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 64\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499490 -> initscore=-0.002041\n",
            "[LightGBM] [Info] Start training from score -0.002041\n",
            "\n",
            "Voting Ensemble Metrics:\n",
            "Accuracy: 0.9589304203946982\n",
            "Precision: 0.9548586129982208\n",
            "Recall: 0.9635066540674329\n",
            "F1 Score: 0.9590941883542434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Dataset/Features/merged_gamma_a_c.csv'\n",
        "merged_gamma_a_c = pd.read_csv(path)\n",
        "# merged_gamma_a_c=merged_gamma_a_c.drop(columns=['X_PS','Y_PS','nd_PS'], axis=False)\n",
        "\n",
        "path = '/content/drive/MyDrive/Dataset/Features/Katz_Fd_Features_a_c.csv'\n",
        "Katz_Fd_Features_a_c = pd.read_csv(path)\n",
        "\n",
        "merged_gamma_katz_a_c = pd.concat([merged_gamma_a_c,Katz_Fd_Features_a_c], axis=1)\n",
        "# merged_beta_gamma_a_c\n",
        "merged_gamma_katz_a_c.drop('label', axis=1, inplace=True)\n",
        "merged_gamma_katz_a_c['label']='normal'\n",
        "merged_gamma_katz_a_c.loc[0:3810, 'label'] = 'addicted'\n",
        "merged_gamma_katz_a_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "O9o0KlM2bt6T",
        "outputId": "d93c76cb-cc05-4150-bf52-ffa3d16a996f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        FP1_PS     FP2_PS      F7_PS       F8_PS    AF1_PS     AF2_PS  \\\n",
              "0     5.867765  16.136485  14.419578  107.004679  4.771000  10.412779   \n",
              "1     4.788753  11.568614  14.381443   75.048537  2.176075   8.500067   \n",
              "2     6.297802  29.544646  13.712807   97.931325  4.131878  13.930406   \n",
              "3     4.348968   9.195677  10.247385   62.184384  2.506088   6.808748   \n",
              "4     7.698942  15.086431  20.116347   61.128746  6.571280   8.982171   \n",
              "...        ...        ...        ...         ...       ...        ...   \n",
              "7617  2.437103   2.691105   9.169849    2.129555  1.467451   1.610917   \n",
              "7618  0.897495   1.245264   3.604244    3.566347  1.042233   1.365339   \n",
              "7619  1.251944   1.448347   6.375324    4.212090  0.632365   0.651843   \n",
              "7620  0.000000   0.000000   0.000000    0.000000  0.000000   0.000000   \n",
              "7621  3.617902   3.738929   5.852530    5.559126  3.810300   3.586122   \n",
              "\n",
              "         FZ_PS     F4_PS     F3_PS    FC6_PS  ...    FCZ_PS    POZ_PS  \\\n",
              "0     2.264702  4.967259  4.718617  2.227520  ...  0.639929  3.175360   \n",
              "1     1.558222  4.906503  3.750594  1.237990  ...  0.481474  1.360249   \n",
              "2     1.443750  4.954165  4.627834  2.631432  ...  0.403271  1.391440   \n",
              "3     1.321086  3.921911  3.681952  1.816489  ...  0.450695  1.121842   \n",
              "4     3.578223  4.040258  6.796313  2.204725  ...  1.011451  3.663678   \n",
              "...        ...       ...       ...       ...  ...       ...       ...   \n",
              "7617  0.581611  2.188392  2.580653  1.218395  ...  0.227139  3.721454   \n",
              "7618  0.834950  1.492575  0.902565  1.093884  ...  0.398802  3.180998   \n",
              "7619  0.297628  0.621490  0.765336  1.009508  ...  0.132006  1.298873   \n",
              "7620  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
              "7621  3.760634  3.979930  5.524031  3.403491  ...  3.155204  4.027627   \n",
              "\n",
              "         OZ_PS     P2_PS     P1_PS    CPZ_PS     nd_PS      Y_PS       FP2  \\\n",
              "0     7.257440  1.171091  1.727645  0.303052  5.626485  6.090333  1.655864   \n",
              "1     3.002968  0.452312  0.873387  0.169722  4.693551  3.472028  1.367933   \n",
              "2     2.908869  0.790318  1.077771  0.227142  6.266331  3.612442  1.584968   \n",
              "3     2.162650  0.753562  0.999099  0.180620  4.211706  6.950914  1.282758   \n",
              "4     5.646425  1.918202  2.340282  0.437771  7.413797  7.107321  1.461674   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7617  4.377724  1.713244  1.729774  0.453551  5.866098  3.061931  1.538744   \n",
              "7618  2.880482  2.019003  1.853624  0.785453  2.408728  3.512361  1.716444   \n",
              "7619  1.126842  0.855509  0.550932  0.247462  1.363607  3.663259  1.556286   \n",
              "7620  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7621  3.094130  2.927279  3.796067  3.164739  3.551407  9.684160  1.598684   \n",
              "\n",
              "         label  \n",
              "0     addicted  \n",
              "1     addicted  \n",
              "2     addicted  \n",
              "3     addicted  \n",
              "4     addicted  \n",
              "...        ...  \n",
              "7617    normal  \n",
              "7618    normal  \n",
              "7619    normal  \n",
              "7620    normal  \n",
              "7621    normal  \n",
              "\n",
              "[7622 rows x 66 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc725dc3-bfda-4ca6-8136-558f81eb8166\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FP1_PS</th>\n",
              "      <th>FP2_PS</th>\n",
              "      <th>F7_PS</th>\n",
              "      <th>F8_PS</th>\n",
              "      <th>AF1_PS</th>\n",
              "      <th>AF2_PS</th>\n",
              "      <th>FZ_PS</th>\n",
              "      <th>F4_PS</th>\n",
              "      <th>F3_PS</th>\n",
              "      <th>FC6_PS</th>\n",
              "      <th>...</th>\n",
              "      <th>FCZ_PS</th>\n",
              "      <th>POZ_PS</th>\n",
              "      <th>OZ_PS</th>\n",
              "      <th>P2_PS</th>\n",
              "      <th>P1_PS</th>\n",
              "      <th>CPZ_PS</th>\n",
              "      <th>nd_PS</th>\n",
              "      <th>Y_PS</th>\n",
              "      <th>FP2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.867765</td>\n",
              "      <td>16.136485</td>\n",
              "      <td>14.419578</td>\n",
              "      <td>107.004679</td>\n",
              "      <td>4.771000</td>\n",
              "      <td>10.412779</td>\n",
              "      <td>2.264702</td>\n",
              "      <td>4.967259</td>\n",
              "      <td>4.718617</td>\n",
              "      <td>2.227520</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639929</td>\n",
              "      <td>3.175360</td>\n",
              "      <td>7.257440</td>\n",
              "      <td>1.171091</td>\n",
              "      <td>1.727645</td>\n",
              "      <td>0.303052</td>\n",
              "      <td>5.626485</td>\n",
              "      <td>6.090333</td>\n",
              "      <td>1.655864</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.788753</td>\n",
              "      <td>11.568614</td>\n",
              "      <td>14.381443</td>\n",
              "      <td>75.048537</td>\n",
              "      <td>2.176075</td>\n",
              "      <td>8.500067</td>\n",
              "      <td>1.558222</td>\n",
              "      <td>4.906503</td>\n",
              "      <td>3.750594</td>\n",
              "      <td>1.237990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.481474</td>\n",
              "      <td>1.360249</td>\n",
              "      <td>3.002968</td>\n",
              "      <td>0.452312</td>\n",
              "      <td>0.873387</td>\n",
              "      <td>0.169722</td>\n",
              "      <td>4.693551</td>\n",
              "      <td>3.472028</td>\n",
              "      <td>1.367933</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.297802</td>\n",
              "      <td>29.544646</td>\n",
              "      <td>13.712807</td>\n",
              "      <td>97.931325</td>\n",
              "      <td>4.131878</td>\n",
              "      <td>13.930406</td>\n",
              "      <td>1.443750</td>\n",
              "      <td>4.954165</td>\n",
              "      <td>4.627834</td>\n",
              "      <td>2.631432</td>\n",
              "      <td>...</td>\n",
              "      <td>0.403271</td>\n",
              "      <td>1.391440</td>\n",
              "      <td>2.908869</td>\n",
              "      <td>0.790318</td>\n",
              "      <td>1.077771</td>\n",
              "      <td>0.227142</td>\n",
              "      <td>6.266331</td>\n",
              "      <td>3.612442</td>\n",
              "      <td>1.584968</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.348968</td>\n",
              "      <td>9.195677</td>\n",
              "      <td>10.247385</td>\n",
              "      <td>62.184384</td>\n",
              "      <td>2.506088</td>\n",
              "      <td>6.808748</td>\n",
              "      <td>1.321086</td>\n",
              "      <td>3.921911</td>\n",
              "      <td>3.681952</td>\n",
              "      <td>1.816489</td>\n",
              "      <td>...</td>\n",
              "      <td>0.450695</td>\n",
              "      <td>1.121842</td>\n",
              "      <td>2.162650</td>\n",
              "      <td>0.753562</td>\n",
              "      <td>0.999099</td>\n",
              "      <td>0.180620</td>\n",
              "      <td>4.211706</td>\n",
              "      <td>6.950914</td>\n",
              "      <td>1.282758</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.698942</td>\n",
              "      <td>15.086431</td>\n",
              "      <td>20.116347</td>\n",
              "      <td>61.128746</td>\n",
              "      <td>6.571280</td>\n",
              "      <td>8.982171</td>\n",
              "      <td>3.578223</td>\n",
              "      <td>4.040258</td>\n",
              "      <td>6.796313</td>\n",
              "      <td>2.204725</td>\n",
              "      <td>...</td>\n",
              "      <td>1.011451</td>\n",
              "      <td>3.663678</td>\n",
              "      <td>5.646425</td>\n",
              "      <td>1.918202</td>\n",
              "      <td>2.340282</td>\n",
              "      <td>0.437771</td>\n",
              "      <td>7.413797</td>\n",
              "      <td>7.107321</td>\n",
              "      <td>1.461674</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7617</th>\n",
              "      <td>2.437103</td>\n",
              "      <td>2.691105</td>\n",
              "      <td>9.169849</td>\n",
              "      <td>2.129555</td>\n",
              "      <td>1.467451</td>\n",
              "      <td>1.610917</td>\n",
              "      <td>0.581611</td>\n",
              "      <td>2.188392</td>\n",
              "      <td>2.580653</td>\n",
              "      <td>1.218395</td>\n",
              "      <td>...</td>\n",
              "      <td>0.227139</td>\n",
              "      <td>3.721454</td>\n",
              "      <td>4.377724</td>\n",
              "      <td>1.713244</td>\n",
              "      <td>1.729774</td>\n",
              "      <td>0.453551</td>\n",
              "      <td>5.866098</td>\n",
              "      <td>3.061931</td>\n",
              "      <td>1.538744</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7618</th>\n",
              "      <td>0.897495</td>\n",
              "      <td>1.245264</td>\n",
              "      <td>3.604244</td>\n",
              "      <td>3.566347</td>\n",
              "      <td>1.042233</td>\n",
              "      <td>1.365339</td>\n",
              "      <td>0.834950</td>\n",
              "      <td>1.492575</td>\n",
              "      <td>0.902565</td>\n",
              "      <td>1.093884</td>\n",
              "      <td>...</td>\n",
              "      <td>0.398802</td>\n",
              "      <td>3.180998</td>\n",
              "      <td>2.880482</td>\n",
              "      <td>2.019003</td>\n",
              "      <td>1.853624</td>\n",
              "      <td>0.785453</td>\n",
              "      <td>2.408728</td>\n",
              "      <td>3.512361</td>\n",
              "      <td>1.716444</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7619</th>\n",
              "      <td>1.251944</td>\n",
              "      <td>1.448347</td>\n",
              "      <td>6.375324</td>\n",
              "      <td>4.212090</td>\n",
              "      <td>0.632365</td>\n",
              "      <td>0.651843</td>\n",
              "      <td>0.297628</td>\n",
              "      <td>0.621490</td>\n",
              "      <td>0.765336</td>\n",
              "      <td>1.009508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.132006</td>\n",
              "      <td>1.298873</td>\n",
              "      <td>1.126842</td>\n",
              "      <td>0.855509</td>\n",
              "      <td>0.550932</td>\n",
              "      <td>0.247462</td>\n",
              "      <td>1.363607</td>\n",
              "      <td>3.663259</td>\n",
              "      <td>1.556286</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7620</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7621</th>\n",
              "      <td>3.617902</td>\n",
              "      <td>3.738929</td>\n",
              "      <td>5.852530</td>\n",
              "      <td>5.559126</td>\n",
              "      <td>3.810300</td>\n",
              "      <td>3.586122</td>\n",
              "      <td>3.760634</td>\n",
              "      <td>3.979930</td>\n",
              "      <td>5.524031</td>\n",
              "      <td>3.403491</td>\n",
              "      <td>...</td>\n",
              "      <td>3.155204</td>\n",
              "      <td>4.027627</td>\n",
              "      <td>3.094130</td>\n",
              "      <td>2.927279</td>\n",
              "      <td>3.796067</td>\n",
              "      <td>3.164739</td>\n",
              "      <td>3.551407</td>\n",
              "      <td>9.684160</td>\n",
              "      <td>1.598684</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7622 rows × 66 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc725dc3-bfda-4ca6-8136-558f81eb8166')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc725dc3-bfda-4ca6-8136-558f81eb8166 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc725dc3-bfda-4ca6-8136-558f81eb8166');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-532a619e-302d-4e32-8171-ce911162e934\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-532a619e-302d-4e32-8171-ce911162e934')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-532a619e-302d-4e32-8171-ce911162e934 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_gamma_katz_a_c"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_gamma_katz_a_c = merged_gamma_katz_a_c.replace(0, merged_gamma_katz_a_c.mean(numeric_only=True))\n",
        "merged_gamma_katz_a_c = merged_gamma_katz_a_c.drop(7620)\n",
        "merged_gamma_katz_a_c = merged_gamma_katz_a_c.reset_index(drop=True)\n",
        "merged_gamma_katz_a_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "KnSuKo2e6zK5",
        "outputId": "d408db0d-589b-4de4-c8e8-06fc1f044a61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        FP1_PS     FP2_PS      F7_PS       F8_PS    AF1_PS     AF2_PS  \\\n",
              "0     5.867765  16.136485  14.419578  107.004679  4.771000  10.412779   \n",
              "1     4.788753  11.568614  14.381443   75.048537  2.176075   8.500067   \n",
              "2     6.297802  29.544646  13.712807   97.931325  4.131878  13.930406   \n",
              "3     4.348968   9.195677  10.247385   62.184384  2.506088   6.808748   \n",
              "4     7.698942  15.086431  20.116347   61.128746  6.571280   8.982171   \n",
              "...        ...        ...        ...         ...       ...        ...   \n",
              "7616  1.684572   1.623761   9.112097    2.782111  1.144432   0.884217   \n",
              "7617  2.437103   2.691105   9.169849    2.129555  1.467451   1.610917   \n",
              "7618  0.897495   1.245264   3.604244    3.566347  1.042233   1.365339   \n",
              "7619  1.251944   1.448347   6.375324    4.212090  0.632365   0.651843   \n",
              "7620  3.617902   3.738929   5.852530    5.559126  3.810300   3.586122   \n",
              "\n",
              "         FZ_PS     F4_PS     F3_PS    FC6_PS  ...    FCZ_PS    POZ_PS  \\\n",
              "0     2.264702  4.967259  4.718617  2.227520  ...  0.639929  3.175360   \n",
              "1     1.558222  4.906503  3.750594  1.237990  ...  0.481474  1.360249   \n",
              "2     1.443750  4.954165  4.627834  2.631432  ...  0.403271  1.391440   \n",
              "3     1.321086  3.921911  3.681952  1.816489  ...  0.450695  1.121842   \n",
              "4     3.578223  4.040258  6.796313  2.204725  ...  1.011451  3.663678   \n",
              "...        ...       ...       ...       ...  ...       ...       ...   \n",
              "7616  1.269359  0.880600  1.205278  0.957745  ...  0.174153  0.867184   \n",
              "7617  0.581611  2.188392  2.580653  1.218395  ...  0.227139  3.721454   \n",
              "7618  0.834950  1.492575  0.902565  1.093884  ...  0.398802  3.180998   \n",
              "7619  0.297628  0.621490  0.765336  1.009508  ...  0.132006  1.298873   \n",
              "7620  3.760634  3.979930  5.524031  3.403491  ...  3.155204  4.027627   \n",
              "\n",
              "         OZ_PS     P2_PS     P1_PS    CPZ_PS     nd_PS      Y_PS       FP2  \\\n",
              "0     7.257440  1.171091  1.727645  0.303052  5.626485  6.090333  1.655864   \n",
              "1     3.002968  0.452312  0.873387  0.169722  4.693551  3.472028  1.367933   \n",
              "2     2.908869  0.790318  1.077771  0.227142  6.266331  3.612442  1.584968   \n",
              "3     2.162650  0.753562  0.999099  0.180620  4.211706  6.950914  1.282758   \n",
              "4     5.646425  1.918202  2.340282  0.437771  7.413797  7.107321  1.461674   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7616  1.234990  0.535141  0.633024  0.261792  1.058754  6.116856  1.819097   \n",
              "7617  4.377724  1.713244  1.729774  0.453551  5.866098  3.061931  1.538744   \n",
              "7618  2.880482  2.019003  1.853624  0.785453  2.408728  3.512361  1.716444   \n",
              "7619  1.126842  0.855509  0.550932  0.247462  1.363607  3.663259  1.556286   \n",
              "7620  3.094130  2.927279  3.796067  3.164739  3.551407  9.684160  1.598684   \n",
              "\n",
              "         label  \n",
              "0     addicted  \n",
              "1     addicted  \n",
              "2     addicted  \n",
              "3     addicted  \n",
              "4     addicted  \n",
              "...        ...  \n",
              "7616    normal  \n",
              "7617    normal  \n",
              "7618    normal  \n",
              "7619    normal  \n",
              "7620    normal  \n",
              "\n",
              "[7621 rows x 66 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d88c8bc-65b0-41f9-9815-1711d1d828aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FP1_PS</th>\n",
              "      <th>FP2_PS</th>\n",
              "      <th>F7_PS</th>\n",
              "      <th>F8_PS</th>\n",
              "      <th>AF1_PS</th>\n",
              "      <th>AF2_PS</th>\n",
              "      <th>FZ_PS</th>\n",
              "      <th>F4_PS</th>\n",
              "      <th>F3_PS</th>\n",
              "      <th>FC6_PS</th>\n",
              "      <th>...</th>\n",
              "      <th>FCZ_PS</th>\n",
              "      <th>POZ_PS</th>\n",
              "      <th>OZ_PS</th>\n",
              "      <th>P2_PS</th>\n",
              "      <th>P1_PS</th>\n",
              "      <th>CPZ_PS</th>\n",
              "      <th>nd_PS</th>\n",
              "      <th>Y_PS</th>\n",
              "      <th>FP2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.867765</td>\n",
              "      <td>16.136485</td>\n",
              "      <td>14.419578</td>\n",
              "      <td>107.004679</td>\n",
              "      <td>4.771000</td>\n",
              "      <td>10.412779</td>\n",
              "      <td>2.264702</td>\n",
              "      <td>4.967259</td>\n",
              "      <td>4.718617</td>\n",
              "      <td>2.227520</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639929</td>\n",
              "      <td>3.175360</td>\n",
              "      <td>7.257440</td>\n",
              "      <td>1.171091</td>\n",
              "      <td>1.727645</td>\n",
              "      <td>0.303052</td>\n",
              "      <td>5.626485</td>\n",
              "      <td>6.090333</td>\n",
              "      <td>1.655864</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.788753</td>\n",
              "      <td>11.568614</td>\n",
              "      <td>14.381443</td>\n",
              "      <td>75.048537</td>\n",
              "      <td>2.176075</td>\n",
              "      <td>8.500067</td>\n",
              "      <td>1.558222</td>\n",
              "      <td>4.906503</td>\n",
              "      <td>3.750594</td>\n",
              "      <td>1.237990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.481474</td>\n",
              "      <td>1.360249</td>\n",
              "      <td>3.002968</td>\n",
              "      <td>0.452312</td>\n",
              "      <td>0.873387</td>\n",
              "      <td>0.169722</td>\n",
              "      <td>4.693551</td>\n",
              "      <td>3.472028</td>\n",
              "      <td>1.367933</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.297802</td>\n",
              "      <td>29.544646</td>\n",
              "      <td>13.712807</td>\n",
              "      <td>97.931325</td>\n",
              "      <td>4.131878</td>\n",
              "      <td>13.930406</td>\n",
              "      <td>1.443750</td>\n",
              "      <td>4.954165</td>\n",
              "      <td>4.627834</td>\n",
              "      <td>2.631432</td>\n",
              "      <td>...</td>\n",
              "      <td>0.403271</td>\n",
              "      <td>1.391440</td>\n",
              "      <td>2.908869</td>\n",
              "      <td>0.790318</td>\n",
              "      <td>1.077771</td>\n",
              "      <td>0.227142</td>\n",
              "      <td>6.266331</td>\n",
              "      <td>3.612442</td>\n",
              "      <td>1.584968</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.348968</td>\n",
              "      <td>9.195677</td>\n",
              "      <td>10.247385</td>\n",
              "      <td>62.184384</td>\n",
              "      <td>2.506088</td>\n",
              "      <td>6.808748</td>\n",
              "      <td>1.321086</td>\n",
              "      <td>3.921911</td>\n",
              "      <td>3.681952</td>\n",
              "      <td>1.816489</td>\n",
              "      <td>...</td>\n",
              "      <td>0.450695</td>\n",
              "      <td>1.121842</td>\n",
              "      <td>2.162650</td>\n",
              "      <td>0.753562</td>\n",
              "      <td>0.999099</td>\n",
              "      <td>0.180620</td>\n",
              "      <td>4.211706</td>\n",
              "      <td>6.950914</td>\n",
              "      <td>1.282758</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.698942</td>\n",
              "      <td>15.086431</td>\n",
              "      <td>20.116347</td>\n",
              "      <td>61.128746</td>\n",
              "      <td>6.571280</td>\n",
              "      <td>8.982171</td>\n",
              "      <td>3.578223</td>\n",
              "      <td>4.040258</td>\n",
              "      <td>6.796313</td>\n",
              "      <td>2.204725</td>\n",
              "      <td>...</td>\n",
              "      <td>1.011451</td>\n",
              "      <td>3.663678</td>\n",
              "      <td>5.646425</td>\n",
              "      <td>1.918202</td>\n",
              "      <td>2.340282</td>\n",
              "      <td>0.437771</td>\n",
              "      <td>7.413797</td>\n",
              "      <td>7.107321</td>\n",
              "      <td>1.461674</td>\n",
              "      <td>addicted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7616</th>\n",
              "      <td>1.684572</td>\n",
              "      <td>1.623761</td>\n",
              "      <td>9.112097</td>\n",
              "      <td>2.782111</td>\n",
              "      <td>1.144432</td>\n",
              "      <td>0.884217</td>\n",
              "      <td>1.269359</td>\n",
              "      <td>0.880600</td>\n",
              "      <td>1.205278</td>\n",
              "      <td>0.957745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.174153</td>\n",
              "      <td>0.867184</td>\n",
              "      <td>1.234990</td>\n",
              "      <td>0.535141</td>\n",
              "      <td>0.633024</td>\n",
              "      <td>0.261792</td>\n",
              "      <td>1.058754</td>\n",
              "      <td>6.116856</td>\n",
              "      <td>1.819097</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7617</th>\n",
              "      <td>2.437103</td>\n",
              "      <td>2.691105</td>\n",
              "      <td>9.169849</td>\n",
              "      <td>2.129555</td>\n",
              "      <td>1.467451</td>\n",
              "      <td>1.610917</td>\n",
              "      <td>0.581611</td>\n",
              "      <td>2.188392</td>\n",
              "      <td>2.580653</td>\n",
              "      <td>1.218395</td>\n",
              "      <td>...</td>\n",
              "      <td>0.227139</td>\n",
              "      <td>3.721454</td>\n",
              "      <td>4.377724</td>\n",
              "      <td>1.713244</td>\n",
              "      <td>1.729774</td>\n",
              "      <td>0.453551</td>\n",
              "      <td>5.866098</td>\n",
              "      <td>3.061931</td>\n",
              "      <td>1.538744</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7618</th>\n",
              "      <td>0.897495</td>\n",
              "      <td>1.245264</td>\n",
              "      <td>3.604244</td>\n",
              "      <td>3.566347</td>\n",
              "      <td>1.042233</td>\n",
              "      <td>1.365339</td>\n",
              "      <td>0.834950</td>\n",
              "      <td>1.492575</td>\n",
              "      <td>0.902565</td>\n",
              "      <td>1.093884</td>\n",
              "      <td>...</td>\n",
              "      <td>0.398802</td>\n",
              "      <td>3.180998</td>\n",
              "      <td>2.880482</td>\n",
              "      <td>2.019003</td>\n",
              "      <td>1.853624</td>\n",
              "      <td>0.785453</td>\n",
              "      <td>2.408728</td>\n",
              "      <td>3.512361</td>\n",
              "      <td>1.716444</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7619</th>\n",
              "      <td>1.251944</td>\n",
              "      <td>1.448347</td>\n",
              "      <td>6.375324</td>\n",
              "      <td>4.212090</td>\n",
              "      <td>0.632365</td>\n",
              "      <td>0.651843</td>\n",
              "      <td>0.297628</td>\n",
              "      <td>0.621490</td>\n",
              "      <td>0.765336</td>\n",
              "      <td>1.009508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.132006</td>\n",
              "      <td>1.298873</td>\n",
              "      <td>1.126842</td>\n",
              "      <td>0.855509</td>\n",
              "      <td>0.550932</td>\n",
              "      <td>0.247462</td>\n",
              "      <td>1.363607</td>\n",
              "      <td>3.663259</td>\n",
              "      <td>1.556286</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7620</th>\n",
              "      <td>3.617902</td>\n",
              "      <td>3.738929</td>\n",
              "      <td>5.852530</td>\n",
              "      <td>5.559126</td>\n",
              "      <td>3.810300</td>\n",
              "      <td>3.586122</td>\n",
              "      <td>3.760634</td>\n",
              "      <td>3.979930</td>\n",
              "      <td>5.524031</td>\n",
              "      <td>3.403491</td>\n",
              "      <td>...</td>\n",
              "      <td>3.155204</td>\n",
              "      <td>4.027627</td>\n",
              "      <td>3.094130</td>\n",
              "      <td>2.927279</td>\n",
              "      <td>3.796067</td>\n",
              "      <td>3.164739</td>\n",
              "      <td>3.551407</td>\n",
              "      <td>9.684160</td>\n",
              "      <td>1.598684</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7621 rows × 66 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d88c8bc-65b0-41f9-9815-1711d1d828aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d88c8bc-65b0-41f9-9815-1711d1d828aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d88c8bc-65b0-41f9-9815-1711d1d828aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c63dc9c2-5cdc-4302-b213-b2cfa98a4e0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c63dc9c2-5cdc-4302-b213-b2cfa98a4e0f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c63dc9c2-5cdc-4302-b213-b2cfa98a4e0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_gamma_katz_a_c"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'new_dataframe' is your DataFrame\n",
        "X = merged_gamma_katz_a_c.iloc[:, :-1]\n",
        "y = merged_gamma_katz_a_c.iloc[:, -1]\n",
        "\n",
        "# Encode the target variable if it's categorical\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "start_time = time.time()\n",
        "svm_classifier = make_pipeline(StandardScaler(), SVC())\n",
        "svm_predictions = cross_val_predict(svm_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "svm_accuracy = accuracy_score(y_encoded, svm_predictions)\n",
        "svm_precision = precision_score(y_encoded, svm_predictions)\n",
        "svm_recall = recall_score(y_encoded, svm_predictions)\n",
        "svm_f1 = f1_score(y_encoded, svm_predictions)\n",
        "svm_processing_time = time.time() - start_time\n",
        "\n",
        "print(\"SVM Metrics:\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"F1 Score:\", svm_f1)\n",
        "print(\"Processing Time:\", svm_processing_time)\n",
        "\n",
        "# XGBoost\n",
        "start_time = time.time()\n",
        "xgb_classifier = XGBClassifier()\n",
        "xgb_predictions = cross_val_predict(xgb_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "xgb_accuracy = accuracy_score(y_encoded, xgb_predictions)\n",
        "xgb_precision = precision_score(y_encoded, xgb_predictions)\n",
        "xgb_recall = recall_score(y_encoded, xgb_predictions)\n",
        "xgb_f1 = f1_score(y_encoded, xgb_predictions)\n",
        "xgb_processing_time = time.time() - start_time\n",
        "\n",
        "print(\"\\nXGBoost Metrics:\")\n",
        "print(\"Accuracy:\", xgb_accuracy)\n",
        "print(\"Precision:\", xgb_precision)\n",
        "print(\"Recall:\", xgb_recall)\n",
        "print(\"F1 Score:\", xgb_f1)\n",
        "print(\"Processing Time:\", xgb_processing_time)\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "start_time = time.time()\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_predictions = cross_val_predict(rf_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "rf_accuracy = accuracy_score(y_encoded, rf_predictions)\n",
        "rf_precision = precision_score(y_encoded, rf_predictions)\n",
        "rf_recall = recall_score(y_encoded, rf_predictions)\n",
        "rf_f1 = f1_score(y_encoded, rf_predictions)\n",
        "rf_processing_time = time.time() - start_time\n",
        "\n",
        "print(\"\\nRandom Forest Metrics:\")\n",
        "print(\"Accuracy:\", rf_accuracy)\n",
        "print(\"Precision:\", rf_precision)\n",
        "print(\"Recall:\", rf_recall)\n",
        "print(\"F1 Score:\", rf_f1)\n",
        "print(\"Processing Time:\", rf_processing_time)\n",
        "\n",
        "\n",
        "# Ensemble Subspace of k-Nearest Neighbors\n",
        "start_time_ensemble_knn = time.time()\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "ensemble_knn_classifier = BaggingClassifier(base_estimator=knn_classifier, n_estimators=10, random_state=42)\n",
        "\n",
        "ensemble_knn_scores = cross_val_predict(ensemble_knn_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "ensemble_knn_accuracy = accuracy_score(y_encoded, ensemble_knn_scores)\n",
        "ensemble_knn_precision = precision_score(y_encoded, ensemble_knn_scores)\n",
        "ensemble_knn_recall = recall_score(y_encoded, ensemble_knn_scores)\n",
        "ensemble_knn_f1 = f1_score(y_encoded, ensemble_knn_scores)\n",
        "ensemble_knn_processing_time = time.time() - start_time_ensemble_knn\n",
        "\n",
        "print(\"\\nEnsemble Subspace of k-Nearest Neighbors Metrics:\")\n",
        "print(\"Accuracy:\", ensemble_knn_accuracy)\n",
        "print(\"Precision:\", ensemble_knn_precision)\n",
        "print(\"Recall:\", ensemble_knn_recall)\n",
        "print(\"F1 Score:\", ensemble_knn_f1)\n",
        "print(\"Processing Time:\", ensemble_knn_processing_time)\n",
        "\n",
        "# LSTM Model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=input_shape, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Convert DataFrame to numpy array\n",
        "X_np = X.values\n",
        "X_np = X_np.reshape((X_np.shape[0], 1, X_np.shape[1]))\n",
        "\n",
        "# 10-fold cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_idx, test_idx in kfold.split(X_np):\n",
        "    X_train, X_test = X_np[train_idx], X_np[test_idx]\n",
        "    y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
        "\n",
        "    # Create and fit LSTM model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "    lstm_model = create_lstm_model(input_shape)\n",
        "    lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_probs = lstm_model.predict(X_test)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Evaluate metrics\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\nLSTM Metrics:\")\n",
        "print(\"LSTM Model Accuracy:\", np.mean(accuracy_scores))\n",
        "print(\"LSTM Model Precision:\", np.mean(precision_scores))\n",
        "print(\"LSTM Model Recall:\", np.mean(recall_scores))\n",
        "print(\"LSTM Model F1 Score:\", np.mean(f1_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82DmgE9lbw6K",
        "outputId": "316f7458-9626-47e9-e53f-d047f7f6564b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Metrics:\n",
            "Accuracy: 0.8489699514499409\n",
            "Precision: 0.86078697421981\n",
            "Recall: 0.8325459317585302\n",
            "F1 Score: 0.8464309539693129\n",
            "Processing Time: 33.20468091964722\n",
            "\n",
            "XGBoost Metrics:\n",
            "Accuracy: 0.9593229235008529\n",
            "Precision: 0.9581151832460733\n",
            "Recall: 0.9606299212598425\n",
            "F1 Score: 0.9593709043250327\n",
            "Processing Time: 42.085776805877686\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.9301928880724314\n",
            "Precision: 0.9248315189217211\n",
            "Recall: 0.9364829396325459\n",
            "F1 Score: 0.9306207616066771\n",
            "Processing Time: 71.6215431690216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble Subspace of k-Nearest Neighbors Metrics:\n",
            "Accuracy: 0.9431833092769978\n",
            "Precision: 0.9421314480230427\n",
            "Recall: 0.9443569553805774\n",
            "F1 Score: 0.9432428889762747\n",
            "Processing Time: 7.196269273757935\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 1s 6ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "\n",
            "LSTM Metrics:\n",
            "LSTM Model Accuracy: 0.9301923268765717\n",
            "LSTM Model Precision: 0.9370358383490611\n",
            "LSTM Model Recall: 0.9229559170601215\n",
            "LSTM Model F1 Score: 0.9295490726156151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# LightGBM\n",
        "lgb_classifier = lgb.LGBMClassifier()\n",
        "lgb_predictions = cross_val_predict(lgb_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "lgb_accuracy = accuracy_score(y_encoded, lgb_predictions)\n",
        "lgb_precision = precision_score(y_encoded, lgb_predictions)\n",
        "lgb_recall = recall_score(y_encoded, lgb_predictions)\n",
        "lgb_f1 = f1_score(y_encoded, lgb_predictions)\n",
        "\n",
        "print(\"\\nLightGBM Metrics:\")\n",
        "print(\"Accuracy:\", lgb_accuracy)\n",
        "print(\"Precision:\", lgb_precision)\n",
        "print(\"Recall:\", lgb_recall)\n",
        "print(\"F1 Score:\", lgb_f1)\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# CatBoost\n",
        "catboost_classifier = CatBoostClassifier(verbose=0)\n",
        "catboost_predictions = cross_val_predict(catboost_classifier, X, y_encoded, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "catboost_accuracy = accuracy_score(y_encoded, catboost_predictions)\n",
        "catboost_precision = precision_score(y_encoded, catboost_predictions)\n",
        "catboost_recall = recall_score(y_encoded, catboost_predictions)\n",
        "catboost_f1 = f1_score(y_encoded, catboost_predictions)\n",
        "\n",
        "print(\"\\nCatBoost Metrics:\")\n",
        "print(\"Accuracy:\", catboost_accuracy)\n",
        "print(\"Precision:\", catboost_precision)\n",
        "print(\"Recall:\", catboost_recall)\n",
        "print(\"F1 Score:\", catboost_f1)\n"
      ],
      "metadata": {
        "id": "1YmiTZbRlojP",
        "outputId": "df1d9121-34c0-4121-e86a-0241df45fdcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3438, number of negative: 3420\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005783 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6858, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501312 -> initscore=0.005249\n",
            "[LightGBM] [Info] Start training from score 0.005249\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005890 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005964 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3429, number of negative: 3430\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005767 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000292\n",
            "[LightGBM] [Info] Start training from score -0.000292\n",
            "[LightGBM] [Info] Number of positive: 3416, number of negative: 3443\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005906 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498032 -> initscore=-0.007873\n",
            "[LightGBM] [Info] Start training from score -0.007873\n",
            "[LightGBM] [Info] Number of positive: 3421, number of negative: 3438\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005799 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498761 -> initscore=-0.004957\n",
            "[LightGBM] [Info] Start training from score -0.004957\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008674 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3430, number of negative: 3429\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010033 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000292\n",
            "[LightGBM] [Info] Start training from score 0.000292\n",
            "[LightGBM] [Info] Number of positive: 3426, number of negative: 3433\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009236 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499490 -> initscore=-0.002041\n",
            "[LightGBM] [Info] Start training from score -0.002041\n",
            "\n",
            "LightGBM Metrics:\n",
            "Accuracy: 0.9564361632331715\n",
            "Precision: 0.9557127882599581\n",
            "Recall: 0.9572178477690289\n",
            "F1 Score: 0.9564647259375818\n",
            "\n",
            "CatBoost Metrics:\n",
            "Accuracy: 0.9593229235008529\n",
            "Precision: 0.9564423578508086\n",
            "Recall: 0.9624671916010499\n",
            "F1 Score: 0.9594453165881737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape X for CNN input (samples, time steps, features)\n",
        "X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
        "\n",
        "# Convert target variable to categorical\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_reshaped.shape[1], 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"\\nCNN Model Metrics:\")\n",
        "print(f\"Accuracy: {scores[1]}\")\n"
      ],
      "metadata": {
        "id": "5NSR10UyocBb",
        "outputId": "f37e0ee7-07b7-4921-ad43-03fd1939217b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "191/191 [==============================] - 3s 12ms/step - loss: 0.4902 - accuracy: 0.7636 - val_loss: 0.4369 - val_accuracy: 0.8341\n",
            "Epoch 2/10\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.3672 - accuracy: 0.8407 - val_loss: 0.3466 - val_accuracy: 0.8695\n",
            "Epoch 3/10\n",
            "191/191 [==============================] - 2s 12ms/step - loss: 0.2989 - accuracy: 0.8740 - val_loss: 0.3074 - val_accuracy: 0.8977\n",
            "Epoch 4/10\n",
            "191/191 [==============================] - 3s 17ms/step - loss: 0.2779 - accuracy: 0.8932 - val_loss: 0.2732 - val_accuracy: 0.9089\n",
            "Epoch 5/10\n",
            "191/191 [==============================] - 3s 15ms/step - loss: 0.2258 - accuracy: 0.9113 - val_loss: 0.2688 - val_accuracy: 0.9174\n",
            "Epoch 6/10\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.1946 - accuracy: 0.9245 - val_loss: 0.2594 - val_accuracy: 0.9292\n",
            "Epoch 7/10\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.1771 - accuracy: 0.9316 - val_loss: 0.2592 - val_accuracy: 0.9174\n",
            "Epoch 8/10\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.1613 - accuracy: 0.9390 - val_loss: 0.2435 - val_accuracy: 0.9423\n",
            "Epoch 9/10\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.1418 - accuracy: 0.9508 - val_loss: 0.2486 - val_accuracy: 0.9370\n",
            "Epoch 10/10\n",
            "191/191 [==============================] - 3s 14ms/step - loss: 0.1335 - accuracy: 0.9529 - val_loss: 0.2580 - val_accuracy: 0.9469\n",
            "\n",
            "CNN Model Metrics:\n",
            "Accuracy: 0.9468852281570435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X to fit into CNN\n",
        "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
        "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Build CNN model\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "cnn_predictions = cnn_model.predict(X_test_cnn)\n",
        "cnn_predictions = (cnn_predictions > 0.5).astype(int)\n",
        "\n",
        "cnn_accuracy = accuracy_score(y_test, cnn_predictions)\n",
        "cnn_precision = precision_score(y_test, cnn_predictions)\n",
        "cnn_recall = recall_score(y_test, cnn_predictions)\n",
        "cnn_f1 = f1_score(y_test, cnn_predictions)\n",
        "\n",
        "print(\"\\nCNN Metrics:\")\n",
        "print(\"Accuracy:\", cnn_accuracy)\n",
        "print(\"Precision:\", cnn_precision)\n",
        "print(\"Recall:\", cnn_recall)\n",
        "print(\"F1 Score:\", cnn_f1)\n"
      ],
      "metadata": {
        "id": "jJFmH-MEos9i",
        "outputId": "4a63f9cb-221e-4a7a-8934-d1c2c23094d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 6s 22ms/step - loss: 0.6720 - accuracy: 0.6529 - val_loss: 0.5341 - val_accuracy: 0.7246\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 2s 12ms/step - loss: 0.5081 - accuracy: 0.7479 - val_loss: 0.4146 - val_accuracy: 0.8246\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 2s 13ms/step - loss: 0.4469 - accuracy: 0.7927 - val_loss: 0.3603 - val_accuracy: 0.8557\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 3s 19ms/step - loss: 0.3680 - accuracy: 0.8323 - val_loss: 0.2981 - val_accuracy: 0.8836\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 0.3315 - accuracy: 0.8693 - val_loss: 0.2675 - val_accuracy: 0.9016\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 2s 12ms/step - loss: 0.2972 - accuracy: 0.8817 - val_loss: 0.2440 - val_accuracy: 0.9066\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 2s 12ms/step - loss: 0.2650 - accuracy: 0.8946 - val_loss: 0.2287 - val_accuracy: 0.9328\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 2s 12ms/step - loss: 0.2380 - accuracy: 0.9021 - val_loss: 0.2035 - val_accuracy: 0.9262\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 2s 12ms/step - loss: 0.2022 - accuracy: 0.9196 - val_loss: 0.2063 - val_accuracy: 0.9279\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 3s 16ms/step - loss: 0.2004 - accuracy: 0.9229 - val_loss: 0.2181 - val_accuracy: 0.9246\n",
            "48/48 [==============================] - 0s 7ms/step\n",
            "\n",
            "CNN Metrics:\n",
            "Accuracy: 0.9101639344262296\n",
            "Precision: 0.9054054054054054\n",
            "Recall: 0.9090909090909091\n",
            "F1 Score: 0.9072444143534191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Define individual models\n",
        "xgb_classifier = XGBClassifier()\n",
        "lgb_classifier = lgb.LGBMClassifier()\n",
        "catboost_classifier = CatBoostClassifier(verbose=0)\n",
        "\n",
        "# Define voting classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_classifier),\n",
        "        ('lgb', lgb_classifier),\n",
        "        ('catboost', catboost_classifier)\n",
        "    ],\n",
        "    voting='soft'  # 'hard' for majority voting, 'soft' for weighted probabilities\n",
        ")\n",
        "\n",
        "# Define k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score),\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1': make_scorer(f1_score)}\n",
        "\n",
        "voting_scores = cross_validate(voting_classifier, X, y_encoded, cv=kf, scoring=scoring)\n",
        "\n",
        "print(\"\\nVoting Ensemble Metrics:\")\n",
        "print(\"Accuracy:\", np.mean(voting_scores['test_accuracy']))\n",
        "print(\"Precision:\", np.mean(voting_scores['test_precision']))\n",
        "print(\"Recall:\", np.mean(voting_scores['test_recall']))\n",
        "print(\"F1 Score:\", np.mean(voting_scores['test_f1']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMXnCtRLciRW",
        "outputId": "c74676c1-53e4-4c3b-bc9e-c565f65756f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3438, number of negative: 3420\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6858, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501312 -> initscore=0.005249\n",
            "[LightGBM] [Info] Start training from score 0.005249\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005861 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3420, number of negative: 3439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498615 -> initscore=-0.005540\n",
            "[LightGBM] [Info] Start training from score -0.005540\n",
            "[LightGBM] [Info] Number of positive: 3429, number of negative: 3430\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005937 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000292\n",
            "[LightGBM] [Info] Start training from score -0.000292\n",
            "[LightGBM] [Info] Number of positive: 3416, number of negative: 3443\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005985 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498032 -> initscore=-0.007873\n",
            "[LightGBM] [Info] Start training from score -0.007873\n",
            "[LightGBM] [Info] Number of positive: 3421, number of negative: 3438\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006058 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498761 -> initscore=-0.004957\n",
            "[LightGBM] [Info] Start training from score -0.004957\n",
            "[LightGBM] [Info] Number of positive: 3445, number of negative: 3414\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005808 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502260 -> initscore=0.009039\n",
            "[LightGBM] [Info] Start training from score 0.009039\n",
            "[LightGBM] [Info] Number of positive: 3430, number of negative: 3429\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000292\n",
            "[LightGBM] [Info] Start training from score 0.000292\n",
            "[LightGBM] [Info] Number of positive: 3426, number of negative: 3433\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009595 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 16575\n",
            "[LightGBM] [Info] Number of data points in the train set: 6859, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499490 -> initscore=-0.002041\n",
            "[LightGBM] [Info] Start training from score -0.002041\n",
            "\n",
            "Voting Ensemble Metrics:\n",
            "Accuracy: 0.9610289539495638\n",
            "Precision: 0.9598197810414941\n",
            "Recall: 0.9625270635694496\n",
            "F1 Score: 0.9610977460751318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = '/content/drive/MyDrive/Dataset/Features/merged_beta_a_c.csv'\n",
        "# merged_beta_a_c = pd.read_csv(path)\n",
        "# merged_beta_a_c"
      ],
      "metadata": {
        "id": "Qf4YkT1KVytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_beta_a_c = merged_beta_a_c.replace(0, merged_beta_a_c.mean(numeric_only=True))\n",
        "# merged_gamma_a_c = merged_gamma_a_c.drop(7620)\n",
        "# merged_gamma_a_c = merged_gamma_a_c.reset_index(drop=True)\n",
        "# merged_beta_a_c"
      ],
      "metadata": {
        "id": "21SmfdxKd_R8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}